{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Segmentation\n",
    "\n",
    "In this guide, we demonstrate how to do document segmentation using structured output from an LLM. We'll be using command-r-plus - one of Cohere's latest LLMs with 128k context length and testing the approach on an article explaining the Transformer architecture. The same approach to document segmentation can be applied to any other domain where we need to break down a complex long document into smaller chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "Sometimes we need a way to split the document into meaningful parts that center around a single key concept/idea. Simple length-based / rule-based text-splitters are not reliable enough. Consider the cases where documents contain code snippets or math equations - we don't want to split those on '\\n\\n' or have to write extensive rules for different types of documents. It turns out that LLMs with sufficiently long context length are well suited for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Data Structures\n",
    "\n",
    "First, we need to define a Section class for each of the document's segments. StructuredDocument class will then encapsulate a list of these sections.\n",
    "\n",
    "Note that in order to avoid LLM regenerating the content of each section, we can simply enumerate each line of the input document and then ask LLM to segment it by providing start-end line numbers for each section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Section(BaseModel):\n",
    "    title: str = Field(description=\"main topic of this section of the document\")\n",
    "    start_index: int = Field(description=\"line number where the section begins\")\n",
    "    end_index: int = Field(description=\"line number where the section ends\")\n",
    "\n",
    "\n",
    "class StructuredDocument(BaseModel):\n",
    "    \"\"\"obtains meaningful sections, each centered around a single concept/topic\"\"\"\n",
    "    sections: List[Section] = Field(description=\"a list of sections of the document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Preprocessing\n",
    "\n",
    "Preprocess the input document by prepending each line with its number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_with_lines(document):\n",
    "    document_lines = document.split(\"\\n\")\n",
    "    document_with_line_numbers = \"\"\n",
    "    line2text = {}\n",
    "    for i, line in enumerate(document_lines):\n",
    "        document_with_line_numbers += f\"[{i}] {line}\\n\"\n",
    "        line2text[i] = line\n",
    "    return document_with_line_numbers, line2text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation\n",
    "\n",
    "Next use a Cohere client to extract StructuredDocument from the preprocessed doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure COHERE_API_KEY is in api_keys.env\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../api_keys.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "client = instructor.from_cohere(cohere.Client(api_key=os.getenv(\"COHERE_API_KEY\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are a world class educator working on organizing your lecture notes.\n",
    "Read the document below and extract a StructuredDocument object from it where each section of the document is centered around a single concept/topic that can be taught in one lesson.\n",
    "Each line of the document is marked with its line number in square brackets (e.g. [1], [2], [3], etc). Use the line numbers to indicate section start and end.\n",
    "\"\"\"\n",
    "\n",
    "def get_structured_document(document_with_line_numbers) -> StructuredDocument:\n",
    "    return client.chat.completions.create(\n",
    "        model=\"command-r-plus\",\n",
    "        response_model=StructuredDocument,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": document_with_line_numbers,\n",
    "            },\n",
    "        ],\n",
    "    )  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to get back the section text based on the start/end indices and our line2text dict from the preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sections_text(structured_doc, line2text):\n",
    "    segments = []\n",
    "    for s in structured_doc.sections:\n",
    "        contents = []\n",
    "        for line_id in range(s.start_index, s.end_index):\n",
    "                contents.append(line2text.get(line_id, ''))\n",
    "        segments.append({\n",
    "            \"title\": s.title,\n",
    "            \"content\": \"\\n\".join(contents),\n",
    "            \"start\": s.start_index,\n",
    "            \"end\": s.end_index\n",
    "        })\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Here's an example of using these classes and functions to segment a tutorial on Transformers from Sebastian Raschka. We can use trafilatura package to scrape the web page content of the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Multi-Head Attention\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Multi-Head Attention\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Multi-Head Attention\n",
       "In the very first figure, at the top of this article, we saw that transformers use a module called multi-head \n",
       "attention. How does that relate to the self-attention mechanism <span style=\"font-weight: bold\">(</span>scaled-dot product attention<span style=\"font-weight: bold\">)</span> we walked through \n",
       "above?\n",
       "In the scaled dot-product attention, the input sequence was transformed using three matrices representing the \n",
       "query, key, and value. These three matrices can be considered as a single attention head in the context of \n",
       "multi-head attention. The figure below summarizes this single attention head we covered previously:\n",
       "As its name implies, multi-head attention involves multiple such heads, each consisting of query, key, and value \n",
       "matrices. This concept is similar to the use of multiple kernels in convolutional neural networks.\n",
       "To illustrate this in code, suppose we have <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> attention heads, so we now extend the \\<span style=\"font-weight: bold\">(</span>d' \\times d\\<span style=\"font-weight: bold\">)</span> dimensional \n",
       "weight matrices so \\<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> \\times d' \\times d\\<span style=\"font-weight: bold\">)</span>:\n",
       "In:\n",
       "h = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "multihead_W_query = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.nn.Parameter</span><span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.rand</span><span style=\"font-weight: bold\">(</span>h, d_q, d<span style=\"font-weight: bold\">))</span>\n",
       "multihead_W_key = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.nn.Parameter</span><span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.rand</span><span style=\"font-weight: bold\">(</span>h, d_k, d<span style=\"font-weight: bold\">))</span>\n",
       "multihead_W_value = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.nn.Parameter</span><span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.rand</span><span style=\"font-weight: bold\">(</span>h, d_v, d<span style=\"font-weight: bold\">))</span>\n",
       "Consequently, each query element is now \\<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> \\times d_q\\<span style=\"font-weight: bold\">)</span> dimensional, where \\<span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">d_q</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span>\\<span style=\"font-weight: bold\">)</span> <span style=\"font-weight: bold\">(</span>here, let’s keep the focus \n",
       "on the 3rd element corresponding to index position <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>:\n",
       "In:\n",
       "multihead_query_2 = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">multihead_W_query.matmul</span><span style=\"font-weight: bold\">(</span>x_2<span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">print</span><span style=\"font-weight: bold\">(</span>multihead_query_2.shape<span style=\"font-weight: bold\">)</span>\n",
       "Out:\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span><span style=\"font-weight: bold\">])</span>\n",
       "We can then obtain the keys and values in a similar fashion:\n",
       "In:\n",
       "multihead_key_2 = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">multihead_W_key.matmul</span><span style=\"font-weight: bold\">(</span>x_2<span style=\"font-weight: bold\">)</span>\n",
       "multihead_value_2 = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">multihead_W_value.matmul</span><span style=\"font-weight: bold\">(</span>x_2<span style=\"font-weight: bold\">)</span>\n",
       "Now, these key and value elements are specific to the query element. But, similar to earlier, we will also need the\n",
       "value and keys for the other sequence elements in order to compute the attention scores for the query. We can do \n",
       "this is by expanding the input sequence embeddings to size <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, i.e., the number of attention heads:\n",
       "In:\n",
       "stacked_inputs = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">embedded_sentence.T.repeat</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">print</span><span style=\"font-weight: bold\">(</span>stacked_inputs.shape<span style=\"font-weight: bold\">)</span>\n",
       "Out:\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">])</span>\n",
       "Now, we can compute all the keys and values using via <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.bmm</span><span style=\"font-weight: bold\">()</span>\n",
       "<span style=\"font-weight: bold\">(</span> batch matrix multiplication<span style=\"font-weight: bold\">)</span>:\n",
       "In:\n",
       "multihead_keys = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.bmm</span><span style=\"font-weight: bold\">(</span>multihead_W_key, stacked_inputs<span style=\"font-weight: bold\">)</span>\n",
       "multihead_values = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.bmm</span><span style=\"font-weight: bold\">(</span>multihead_W_value, stacked_inputs<span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">print</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"multihead_keys.shape:\"</span>, multihead_keys.shape<span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">print</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"multihead_values.shape:\"</span>, multihead_values.shape<span style=\"font-weight: bold\">)</span>\n",
       "Out:\n",
       "multihead_keys.shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">])</span>\n",
       "multihead_values.shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">])</span>\n",
       "We now have tensors that represent the three attention heads in their first dimension. The third and second \n",
       "dimensions refer to the number of words and the embedding size, respectively. To make the values and keys more \n",
       "intuitive to interpret, we will swap the second and third dimensions, resulting in tensors with the same \n",
       "dimensional structure as the original input sequence, embedded_sentence\n",
       ":\n",
       "In:\n",
       "multihead_keys = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">multihead_keys.permute</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "multihead_values = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">multihead_values.permute</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">print</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"multihead_keys.shape:\"</span>, multihead_keys.shape<span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">print</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"multihead_values.shape:\"</span>, multihead_values.shape<span style=\"font-weight: bold\">)</span>\n",
       "Out:\n",
       "multihead_keys.shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span><span style=\"font-weight: bold\">])</span>\n",
       "multihead_values.shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Multi-Head Attention\n",
       "In the very first figure, at the top of this article, we saw that transformers use a module called multi-head \n",
       "attention. How does that relate to the self-attention mechanism \u001b[1m(\u001b[0mscaled-dot product attention\u001b[1m)\u001b[0m we walked through \n",
       "above?\n",
       "In the scaled dot-product attention, the input sequence was transformed using three matrices representing the \n",
       "query, key, and value. These three matrices can be considered as a single attention head in the context of \n",
       "multi-head attention. The figure below summarizes this single attention head we covered previously:\n",
       "As its name implies, multi-head attention involves multiple such heads, each consisting of query, key, and value \n",
       "matrices. This concept is similar to the use of multiple kernels in convolutional neural networks.\n",
       "To illustrate this in code, suppose we have \u001b[1;36m3\u001b[0m attention heads, so we now extend the \\\u001b[1m(\u001b[0md' \\times d\\\u001b[1m)\u001b[0m dimensional \n",
       "weight matrices so \\\u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m \\times d' \\times d\\\u001b[1m)\u001b[0m:\n",
       "In:\n",
       "h = \u001b[1;36m3\u001b[0m\n",
       "multihead_W_query = \u001b[1;35mtorch.nn.Parameter\u001b[0m\u001b[1m(\u001b[0m\u001b[1;35mtorch.rand\u001b[0m\u001b[1m(\u001b[0mh, d_q, d\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "multihead_W_key = \u001b[1;35mtorch.nn.Parameter\u001b[0m\u001b[1m(\u001b[0m\u001b[1;35mtorch.rand\u001b[0m\u001b[1m(\u001b[0mh, d_k, d\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "multihead_W_value = \u001b[1;35mtorch.nn.Parameter\u001b[0m\u001b[1m(\u001b[0m\u001b[1;35mtorch.rand\u001b[0m\u001b[1m(\u001b[0mh, d_v, d\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "Consequently, each query element is now \\\u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m \\times d_q\\\u001b[1m)\u001b[0m dimensional, where \\\u001b[1m(\u001b[0m\u001b[33md_q\u001b[0m=\u001b[1;36m24\u001b[0m\\\u001b[1m)\u001b[0m \u001b[1m(\u001b[0mhere, let’s keep the focus \n",
       "on the 3rd element corresponding to index position \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m:\n",
       "In:\n",
       "multihead_query_2 = \u001b[1;35mmultihead_W_query.matmul\u001b[0m\u001b[1m(\u001b[0mx_2\u001b[1m)\u001b[0m\n",
       "\u001b[1;35mprint\u001b[0m\u001b[1m(\u001b[0mmultihead_query_2.shape\u001b[1m)\u001b[0m\n",
       "Out:\n",
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m24\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "We can then obtain the keys and values in a similar fashion:\n",
       "In:\n",
       "multihead_key_2 = \u001b[1;35mmultihead_W_key.matmul\u001b[0m\u001b[1m(\u001b[0mx_2\u001b[1m)\u001b[0m\n",
       "multihead_value_2 = \u001b[1;35mmultihead_W_value.matmul\u001b[0m\u001b[1m(\u001b[0mx_2\u001b[1m)\u001b[0m\n",
       "Now, these key and value elements are specific to the query element. But, similar to earlier, we will also need the\n",
       "value and keys for the other sequence elements in order to compute the attention scores for the query. We can do \n",
       "this is by expanding the input sequence embeddings to size \u001b[1;36m3\u001b[0m, i.e., the number of attention heads:\n",
       "In:\n",
       "stacked_inputs = \u001b[1;35membedded_sentence.T.repeat\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1;35mprint\u001b[0m\u001b[1m(\u001b[0mstacked_inputs.shape\u001b[1m)\u001b[0m\n",
       "Out:\n",
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "Now, we can compute all the keys and values using via \u001b[1;35mtorch.bmm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m(\u001b[0m batch matrix multiplication\u001b[1m)\u001b[0m:\n",
       "In:\n",
       "multihead_keys = \u001b[1;35mtorch.bmm\u001b[0m\u001b[1m(\u001b[0mmultihead_W_key, stacked_inputs\u001b[1m)\u001b[0m\n",
       "multihead_values = \u001b[1;35mtorch.bmm\u001b[0m\u001b[1m(\u001b[0mmultihead_W_value, stacked_inputs\u001b[1m)\u001b[0m\n",
       "\u001b[1;35mprint\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"multihead_keys.shape:\"\u001b[0m, multihead_keys.shape\u001b[1m)\u001b[0m\n",
       "\u001b[1;35mprint\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"multihead_values.shape:\"\u001b[0m, multihead_values.shape\u001b[1m)\u001b[0m\n",
       "Out:\n",
       "multihead_keys.shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m24\u001b[0m, \u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "multihead_values.shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m28\u001b[0m, \u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "We now have tensors that represent the three attention heads in their first dimension. The third and second \n",
       "dimensions refer to the number of words and the embedding size, respectively. To make the values and keys more \n",
       "intuitive to interpret, we will swap the second and third dimensions, resulting in tensors with the same \n",
       "dimensional structure as the original input sequence, embedded_sentence\n",
       ":\n",
       "In:\n",
       "multihead_keys = \u001b[1;35mmultihead_keys.permute\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "multihead_values = \u001b[1;35mmultihead_values.permute\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1;35mprint\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"multihead_keys.shape:\"\u001b[0m, multihead_keys.shape\u001b[1m)\u001b[0m\n",
       "\u001b[1;35mprint\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"multihead_values.shape:\"\u001b[0m, multihead_values.shape\u001b[1m)\u001b[0m\n",
       "Out:\n",
       "multihead_keys.shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m24\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "multihead_values.shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m28\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trafilatura import fetch_url, extract\n",
    "from rich import print\n",
    "\n",
    "url='https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html'\n",
    "document = extract(fetch_url(url))\n",
    "\n",
    "document_with_line_numbers, line2text = doc_with_lines(document)\n",
    "structured_doc = get_structured_document(document_with_line_numbers)\n",
    "segments = get_sections_text(structured_doc, line2text)\n",
    "\n",
    "print(segments[5]['title'])\n",
    "print(segments[5]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
