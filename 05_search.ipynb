{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Segmenting Search Queries\n",
                "\n",
                "In this example, we will demonstrate how to leverage the `MultiTask` and `enum.Enum` features of OpenAI Function Call to segment search queries. We will define the necessary structures using Pydantic and demonstrate how to segment queries into multiple sub-queries and execute them in parallel with `asyncio`.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Motivation\n",
                "\n",
                "Extracting a list of tasks from text is a common use case for leveraging language models. This pattern can be applied to various applications, such as virtual assistants like Siri or Alexa, where understanding user intent and breaking down requests into actionable tasks is crucial. In this example, we will demonstrate how to use OpenAI Function Call to segment search queries and execute them in parallel."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Structure of the Data\n",
                "\n",
                "The `Search` class is a Pydantic model that defines the structure of the search query. It has three fields: `query`, and `type`. The `query` field is the query to search for relevant content, and the `type` field is the type of search. The `execute` method is used to execute the search query."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "import instructor\n",
                "from openai import OpenAI\n",
                "from typing import Iterable, Literal\n",
                "from pydantic import BaseModel, Field\n",
                "from dotenv import load_dotenv"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Load environment variables\n",
                "load_dotenv(\"../api_keys.env\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply the patch to the OpenAI client\n",
                "# enables response_model keyword\n",
                "client = instructor.from_openai(OpenAI())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Search(BaseModel):\n",
                "    query: str = Field(..., description=\"Query to search for relevant content\")\n",
                "    type: Literal[\"web\", \"image\", \"video\"] = Field(..., description=\"Type of search\")\n",
                "\n",
                "    async def execute(self):\n",
                "        print(\n",
                "            f\"Searching for query `{self.query}` using `{self.type}`\"\n",
                "        )\n",
                "\n",
                "def segment(data: str) -> Search:\n",
                "    return client.chat.completions.create(\n",
                "        model=\"gpt-4o\",\n",
                "        response_model=Iterable[Search],\n",
                "        messages=[\n",
                "            {\n",
                "                \"role\": \"user\",\n",
                "                \"content\": f\"Consider the data below: '\\n{data}' and segment it into multiple search queries\",\n",
                "            },\n",
                "        ],\n",
                "        max_tokens=1000,\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{\"query\":\"picture of a cat\",\"type\":\"image\"}\n",
                        "{\"query\":\"video of a dog\",\"type\":\"video\"}\n"
                    ]
                }
            ],
            "source": [
                "# Example usage\n",
                "for search in segment(\"Search for a picture of a cat and a video of a dog\"):\n",
                "    print(search.model_dump_json())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The code above demonstrates how to segment a search query into multiple sub-queries.\n",
                "This example showcases how to use OpenAI Function Call with Pydantic models to segment and structure search queries effectively."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
