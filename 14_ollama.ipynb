{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Structured Outputs with Ollama\n",
                "\n",
                "Open-source LLMS are gaining popularity, and with the release of Ollama's OpenAI compatibility layer, it has become possible to obtain structured outputs using JSON schema.\n",
                "\n",
                "By the end of this blog post, you will learn how to effectively utilize instructor with Ollama. But before we proceed, let's first explore the concept of patching.\n",
                "\n",
                "## Patching\n",
                "\n",
                "Instructor's patch enhances an openai api with the following features:\n",
                "* `response_model` in `create` calls that returns a pydantic model\n",
                "* `max_retries` in `create` calls that retries the call if it fails by using a backoff strategy\n",
                "\n",
                "**Learn More**\n",
                "To learn more, please refer to the docs. To understand the benefits of using Pydantic with Instructor, visit the tips and tricks section of the why use Pydantic page.\n",
                "\n",
                "## Ollama\n",
                "\n",
                "Start by downloading Ollama, and then pull a model such as Llama 3 or Mistral.\n",
                "\n",
                "**Make sure you update your **`ollama` to the latest version!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ollama pull llama3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from openai import OpenAI\n",
                "from pydantic import BaseModel, Field\n",
                "from typing import List\n",
                "import instructor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from dotenv import load_dotenv\n",
                "load_dotenv(\"../api_keys.env\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# enables `response_model` in create call\n",
                "client = instructor.from_openai(\n",
                "    OpenAI(\n",
                "        base_url=\"http://localhost:11434/v1\",\n",
                "        api_key=\"ollama\",  # required, but unused\n",
                "    ),\n",
                "    mode=instructor.Mode.JSON,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Character(BaseModel):\n",
                "    name: str\n",
                "    age: int\n",
                "    fact: List[str] = Field(..., description=\"A list of facts about the character\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "resp = client.chat.completions.create(\n",
                "    model=\"llama3\",\n",
                "    messages=[\n",
                "        {\n",
                "            \"role\": \"user\",\n",
                "            \"content\": \"Tell me about the Harry Potter\",\n",
                "        }\n",
                "    ],\n",
                "    response_model=Character,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(resp.model_dump_json(indent=2))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\"\"\"\n",
                "{\n",
                "  \"name\": \"Harry James Potter\",\n",
                "  \"age\": 37,\n",
                "  \"fact\": [\n",
                "    \"He is the chosen one.\",\n",
                "    \"He has a lightning-shaped scar on his forehead.\",\n",
                "    \"He is the son of James and Lily Potter.\",\n",
                "    \"He attended Hogwarts School of Witchcraft and Wizardry.\",\n",
                "    \"He is a skilled wizard and sorcerer.\",\n",
                "    \"He fought against Lord Voldemort and his followers.\",\n",
                "    \"He has a pet owl named Snowy.\"\n",
                "  ]\n",
                "}\n",
                "\"\"\""
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
